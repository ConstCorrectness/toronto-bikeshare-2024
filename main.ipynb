{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d205086-ce34-4618-99e2-6e9245ffe9ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfolium\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os.path \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ebd37-e1fd-4241-b0ae-d372c8bcb9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stationdf = pd.read_csv('datasets/station_information.csv')   \n",
    "\n",
    "stationdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1044d07-f58a-43c5-aca3-7416f998bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleaning:\n",
    "The first column of `datasets/station_information.csv` corresponds to the label\n",
    "so it's better to use the pd.read_csv(..., index_col=0) named argument to set the index \n",
    "to that column's values\n",
    "\"\"\"\n",
    "\n",
    "stationdf = pd.read_csv('datasets/station_information.csv', index_col=0)\n",
    "\n",
    "\n",
    "stationdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f41575-b40a-4377-8f80-7967666d29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleaning:\n",
    "There's a few columns we're interested in,\n",
    "we could use pd.read_csv(..., usecols=['lat', 'lon', ...etc...]) but\n",
    "instead we'll use pd.DataFrame.drop(columns=[...]) to discard the columns\n",
    "we don't need\n",
    "\"\"\"\n",
    "\n",
    "unneeded_cols = ['altitude', 'capacity', 'is_charging_station', 'rental_methods', 'obcn', 'short_name', '_ride_code_support', 'is_valet_station', 'cross_street', 'groups', 'nearby_distance']\n",
    "\n",
    "cleaned_df = stationdf.drop(columns=unneeded_cols)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d387e-b730-4300-bedc-1307c650414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = cleaned_df[['station_id', 'lat', 'lon']]\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f07901-e061-4496-9626-a386d17ccac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "Information:\n",
    "requests.get(url, params=params) already URL-encodes the params dictionary keys/values\n",
    "but we need to use multiple \"markers\" keys in our query string, so we need\n",
    "to build up the list and use urllib.parse.urlencode() if we use a list\n",
    "\"\"\"\n",
    "\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d6e3d-6599-44d3-8de6-ae523737b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_static_maps_api = 'https://maps.googleapis.com/maps/api/staticmap'\n",
    "\n",
    "markers = [(x, y) for x, y in zip(locations['lat'], locations['lon'])]\n",
    "markers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a00199-933e-4400-b96c-af68b08c0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Information:\n",
    "------------------------------------------------\n",
    "From https://developers.google.com/maps/documentation/maps-static/start#Markers\n",
    "The markers parameter defines a set of one or more markers (map pins) at a set of locations. \n",
    "Each marker defined within a single markers declaration must exhibit the same visual style; if \n",
    "you wish to display markers with different styles, you will need to supply multiple markers parameters \n",
    "with separate style information.\n",
    "\n",
    "The markers parameter takes set of value assignments (marker descriptors) of the following format:\n",
    "\n",
    "markers=markerStyles|markerLocation1| markerLocation2|... etc.\n",
    "\n",
    "The set of markerStyles is declared at the beginning of the markers declaration and consists of zero or \n",
    "more style descriptors separated by the pipe character (|), followed by a set of one or more locations \n",
    "also separated by the pipe character (|).\n",
    "------------------------------------------------\n",
    "\n",
    "\n",
    "latitude and longitude take 6 decimal places, hence the f'{:.6f}' format_spec in the following fstring\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "center_lat = locations['lat'].mean()\n",
    "center_lon = locations['lon'].mean()\n",
    "\n",
    "params = {\n",
    "#    'center': '43.651070,-79.347015',\n",
    "    'center': '43.6742200301605, -79.39451997301134',\n",
    "    'markers': 'color:blue|' + '|'.join([f'{lat:.6f},{lon:.6f}' for lat, lon in markers[:600]]),\n",
    "    'format': 'jpg',\n",
    "#    'scale': 1,\n",
    "    'size': '400x400',\n",
    "    'key': 'AIzaSyCj1qERpT2VI_hOsPonR25vG8b6A-yfMZ8'\n",
    "}\n",
    "len(markers)\n",
    "center_lat, center_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ff3fc-6483-4ff0-a0d4-e59e074ba9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "center_lat = sum(lat for lat, lon in markers) / len(markers)\n",
    "center_lon = sum(lon for lat, lon in markers) / len(markers)\n",
    "\n",
    "(43.67422003016046, -79.3945199730113)\n",
    "ChatGPT gave us this code and the answer is the same as yours, but takes longer to run. A+ Rob\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96119876-c10d-4f0a-b9fa-f56435660e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(google_static_maps_api, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('images/bike_stations.jpg', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3a24a-4ad7-4469-bb9d-5d78b616326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_params = urllib.parse.urlencode(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462a85e-8529-42a1-b318-2b4920fcdf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_ridership_csv():\n",
    "\n",
    "    ridership_csv = glob.glob(\"datasets/bikeshare-ridership-2023/*.csv\")\n",
    "\n",
    "    ridership_df = pd.concat([pd.read_csv(file, encoding = 'cp1252') for file in ridership_csv], ignore_index = True)\n",
    "\n",
    "    ridership_df.to_csv(\"datasets/combined_ridership.csv\", index = False)\n",
    "\n",
    "    print(\" Combined CSV files successfully!\")\n",
    "\n",
    "if os.path.isfile(\"datasets/combined_ridership.csv\"):\n",
    "    print(\"Combined_ridership.csv file already exists\")\n",
    "else:\n",
    "    generate_ridership_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88ae3e-39f5-42ab-9e9b-34b66a3f8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find the number of total rows to determine our sampling frequency\n",
    "rows_df = pd.read_csv(\"datasets/combined_ridership.csv\", encoding='cp1252')\n",
    "\n",
    "row_count = len(rows_df)\n",
    "\n",
    "print(f\"Total number of rows in the CSV: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ef954-9106-4c69-a8aa-7a9ed4365b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We want a systematic sample of 10,000 rows of data\n",
    "\n",
    "Therefore, n = 5,713,141 / 10,000\n",
    "\n",
    "\"\"\"\n",
    "sample_size = 10000\n",
    "interval = row_count / sample_size\n",
    "\n",
    "print(f\"Interval: {interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2059e3-a0e1-44c6-b276-8a604fbe1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ILOC to pickup every 571 row and create new csv file\n",
    "\n",
    "\n",
    "sample_df = rows_df.iloc[::571].copy()\n",
    "\n",
    "if os.path.isfile(\"datasets/sample_every_571_row.csv\"):\n",
    "    print(\"sample_every_571_row.csv file already exists\")\n",
    "else:\n",
    "    sample_df.to_csv(\"datasets/sample_every_571_row.csv\", index=False)\n",
    "    print(\"âœ… Sampled every 571 row and saved to new file!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbca68c-8486-442c-8803-a92b93318f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see what our data looks like in a PD Dataframe\n",
    "\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a54795-df6f-4765-9ec0-6be9e7cffe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data in Start time so the date and time have their own columns (for start and end date/time)\n",
    "\n",
    "if ('Start Date' not in sample_df.columns and 'End Date' not in sample_df.columns and 'Time Start' not in sample_df.columns and 'Time End' not in sample_df.columns):\n",
    "    sample_df.loc[:, 'Start Date'] = pd.to_datetime(sample_df.loc[:, 'Start Time']).dt.date\n",
    "    sample_df.loc[:, 'Time Start'] = pd.to_datetime(sample_df.loc[:, 'Start Time']).dt.time\n",
    "    sample_df.loc[:, 'End Date'] = pd.to_datetime(sample_df.loc[:, 'End Time']).dt.date\n",
    "    sample_df.loc[:, 'Time End'] = pd.to_datetime(sample_df.loc[:, 'End Time']).dt.time\n",
    "\n",
    "\n",
    "    #Drop old Start time and End Time columns and other irrelevant columns\n",
    "    sample_df = sample_df.drop(columns=['Start Time', 'End Time', 'Trip Id'])\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe6a4b-3167-4729-9f4b-461810ef2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find column data types\n",
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059cebc-41fa-454d-8681-f6fa560f1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns for better functionality\n",
    "sample_df.columns = ['Trip id'] + list(sample_df.columns[1:])\n",
    "\n",
    "sample_df = sample_df.fillna({'Trip id': 0})\n",
    "sample_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47659ae3-0bfe-4418-94ba-005e3ba0de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Remove any rows with nan values\n",
    "\n",
    "sample_df = sample_df.dropna(subset=['Start Station Name', 'End Station Name'])\n",
    "sample_df.isnull().sum()\n",
    "sample_df.head()\n",
    "\n",
    "#Test to see if Trip ID column had 0 filled in on the nan rows\n",
    "sample_df.to_csv(\"datasets/test.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26455a-c8b3-4417-95d1-14fb7ea53c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print final \n",
    "print(f\"{len(sample_df)}\")\n",
    "sample_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623b76b-631a-427a-9162-082e12663fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a829d1b-1dad-413d-9fd4-3694cf0acda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns and column names for easier presentation\n",
    "\n",
    "new_order = ['Trip id', 'Start Date', 'Time Start', 'End Date', 'Time End', 'Trip  Duration', 'Start Station Id', 'Start Station Name',\n",
    "             'End Station Id', 'End Station Name', 'User Type', 'Bike Id']\n",
    "\n",
    "sample_df = sample_df[new_order]\n",
    "\n",
    "sample_df.rename(columns={'Trip  Duration': 'Trip Duration (seconds)', 'Start Date': 'Start Date (YYYY-MM-DD)', 'End Date': 'End Date (YYYY-MM-DD)'}, inplace = True)\n",
    "\n",
    "\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfc0d1-c9a7-41c7-8c93-736c60724266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data types\n",
    "sample_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c99a2-3819-4410-8a55-5070107bcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert start date and end date from object to datetime\n",
    "\n",
    "sample_df['Start Date (YYYY-MM-DD)'] = pd.to_datetime(sample_df['Start Date (YYYY-MM-DD)'], format = '%Y-%m-%d')\n",
    "sample_df['End Date (YYYY-MM-DD)'] = pd.to_datetime(sample_df['End Date (YYYY-MM-DD)'], format = '%Y-%m-%d')\n",
    "sample_df['Time Start'] = pd.to_datetime(sample_df['Time Start'], format = '%H:%M:%S')\n",
    "sample_df['Time End'] = pd.to_datetime(sample_df['Time End'], format = '%H:%M:%S')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a3aa95-bec4-438d-9e4a-b4884f9f94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm that there are no more missing values\n",
    "print(sample_df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d697617-0dc8-4462-aa0e-19f48838272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm there are no duplicated rows\n",
    "print(sample_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6eb25-93c1-4157-93a7-aa0ef39ecba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm columns are correct data types\n",
    "\n",
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0730a969-b076-4d9b-9fc3-460324a2adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is now fully cleaned, lets move on to data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b340ad3-adf0-4e0d-82cb-c8601aa04b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the breakdown of casual members vs annual members\n",
    "user_type_counts_df = sample_df['User Type'].value_counts().reset_index()\n",
    "user_type_counts_df.columns = ['User Type', 'Count']\n",
    "print(user_type_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296449c-7a07-45a1-bea2-3a05e9914e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table showing riders by month, as well as the percentage of the overall rides\n",
    "\n",
    "sample_df['Month'] = sample_df['Start Date (YYYY-MM-DD)'].dt.to_period('M')\n",
    "\n",
    "#Group by Month and get count\n",
    "\n",
    "start_date_by_month = sample_df.groupby('Month').size().reset_index(name='Count')\n",
    "# Calculate the percentage for each month\n",
    "start_date_by_month['Percentage'] = (start_date_by_month['Count'] / start_date_by_month['Count'].sum()) * 100\n",
    "\n",
    "# Add a total row\n",
    "total_row = pd.DataFrame({'Month': ['Total'], 'Count': [start_date_by_month['Count'].sum()], 'Percentage': [100]})\n",
    "start_date_by_month = pd.concat([start_date_by_month, total_row], ignore_index=True)\n",
    "\n",
    "print(start_date_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71d19c-3326-4c58-a3b2-14d1b5e875bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â€¢\tIdentify fluctuations in bike usage throughout the year, comparing peak and off-peak seasons.\n",
    "\n",
    "#Table showing riders by month, as well as the percentage of the overall rides\n",
    "\n",
    "sample_df['Month'] = sample_df['Start Date (YYYY-MM-DD)'].dt.to_period('M').astype(str)\n",
    "\n",
    "#Group by Month and get count\n",
    "\n",
    "start_date_by_month_user = sample_df.groupby(['Month', 'User Type']).size().reset_index(name='Count')\n",
    "\n",
    "# Calculate the percentage for each month\n",
    "start_date_by_month_user['Percentage'] = (start_date_by_month_user['Count'] / start_date_by_month_user['Count'].sum()) * 100\n",
    "\n",
    "# Add a total row\n",
    "# Add a total row for each User Type\n",
    "total_row = start_date_by_month_user.groupby('User Type').sum().reset_index()\n",
    "total_row['Month'] = 'Total'\n",
    "total_row['Percentage'] = 100\n",
    "\n",
    "# Add a grand total row for all users\n",
    "grand_total_row = pd.DataFrame({'Month': ['Total'], 'User Type': ['All'], 'Count': [start_date_by_month_user['Count'].sum()], 'Percentage': [100]})\n",
    "\n",
    "# Combine everything\n",
    "final_table = pd.concat([start_date_by_month_user, total_row, grand_total_row], ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "import IPython.display as display\n",
    "display.display(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215d52d-644d-4404-920d-6a804b36a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart_users = final_table.drop(columns='Percentage')  # Drop the 'Percentage' column if it exists\n",
    "\n",
    "# Filter out the 'Total' row\n",
    "bar_chart_users = bar_chart_users[bar_chart_users['Month'] != 'Total']\n",
    "\n",
    "# Pivot the table to have 'User Type' as columns\n",
    "bar_chart_users_pivot = bar_chart_users.pivot_table(index='Month', columns='User Type', values='Count', aggfunc='sum', fill_value=0)\n",
    "\n",
    "# Plot the bar chart with stacking enabled\n",
    "bar_chart = bar_chart_users_pivot.plot(kind='bar', stacked=False, figsize=(10, 6), color=['blue', 'green'])\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Count of User Types by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='User Type', loc='upper left', labels=['Annual Member', 'Casual Member'], fontsize=12, title_fontsize=14)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "    \n",
    "fig = bar_chart.get_figure()\n",
    "fig.savefig('images/fig1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d5372-e7fc-4b8f-8ebd-871647455646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#â€¢\tAnalyze daily and hourly ridership patterns to determine high-demand periods, especially during commute hours.\n",
    "\n",
    "#Look at the day of the week for our sample\n",
    "\n",
    "day_of_week = sample_df[\"Start Date (YYYY-MM-DD)\"].dt.day_name()\n",
    "sample_df['Day of Week'] = sample_df['Start Date (YYYY-MM-DD)'].dt.day_name()\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4cc5e-b963-4ba4-b6a7-ea93dc01e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't get this code to run - want a sum\n",
    "\"\"\"\n",
    "day_counts = sample_df['Day of Week'].value_counts()\n",
    "\n",
    "total_count = day_counts.sum()\n",
    "\n",
    "# Append the total row at the end of the DataFrame\n",
    "total_row = pd.append({'Day of Week': ['Total'], 'Count': [total_count]})\n",
    "day_counts = pd.concat([total_count, total_row], ignore_index=True)\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(day_counts)\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5a134-52e9-4bed-a84d-64cab70a7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_counts = sample_df['Day of Week'].value_counts()\n",
    "\n",
    "# Plot the pie chart\n",
    "pie = day_counts.plot(kind='pie', figsize=(8, 8), autopct='%1.1f%%', startangle=90, cmap='rainbow')\n",
    "\n",
    "# Adding title\n",
    "plt.title('Distribution of Days of the Week')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "fig = pie.get_figure()\n",
    "fig.savefig('images/fig2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229b2c6-b793-454a-82ed-050c4bf9e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f02b0-7b23-4f14-8c59-f8231cee8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_df['day_start'] = sample_df['Time Start'].apply(lambda x: pd.Timedelta(f'{x.hour}:{x.minute}:{x.second}'))\n",
    "\n",
    "\n",
    "sample_df['day_start_hour'] = sample_df['day_start'].dt.components.hours\n",
    "sample_df['day_start_minute'] = sample_df['day_start'].dt.components.minutes\n",
    "sample_df['day_start_seconds'] = sample_df['day_start'].dt.components.seconds\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f0b3b-06cc-4a8f-8369-e8312f5bad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# TODO: Make this nicer!\n",
    "# showing most busy bike use hours.\n",
    "f = sample_df['day_start_hour'].plot(kind='hist', bins=24, color='g')\n",
    "plt.xlabel('Hour of Day') #X-axis label\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(0, 25, 1))\n",
    "plt.title('Distribution of day start hour')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# November, Dec, Jan = Winter\n",
    "# Feb, March, Apr = Spring\n",
    "# May, Jun, Jul = Summer\n",
    "# Aug, Sept Oct = Fall\n",
    "\n",
    "\n",
    "plt.savefig('images/fig3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f997c-6c8d-49a5-9c49-b7fb9b12a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.groupby('Month')['day_start_hour'].sum().plot(kind='bar')\n",
    "plt.savefig('images/fig4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de050fe-6028-4073-b100-6b3752478a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['Month'] = pd.to_datetime(sample_df['Month'], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b8288-b67f-404e-bc3b-a93b93e675a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "sample_df['Season'] = sample_df['Month'].dt.month.map(get_season)\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca155a1e-6a9d-4cf4-b93f-4de0e5896df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df.groupby('Season')['day_start_hour'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40aa70-7280-4487-9e2e-44e9cb692245",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df = sample_df.groupby(['Season', 'Month']).size().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a4e62-28b7-4cae-b638-3d1e21e4bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df['Month_Number'] = season_df['Month'].dt.month\n",
    "\n",
    "\n",
    "season_map = {\n",
    "    0: \"Winter\", 1: \"Winter\", 11: \"Winter\",  # Dec, Jan, Feb\n",
    "    2: \"Spring\", 3: \"Spring\", 4: \"Spring\",  # Mar, Apr, May\n",
    "    5: \"Summer\", 6: \"Summer\", 7: \"Summer\",  # Jun, Jul, Aug\n",
    "    8: \"Fall\", 9: \"Fall\", 10: \"Fall\"        # Sep, Oct, Nov\n",
    "}\n",
    "\n",
    "def month_num_to_name(x):\n",
    "    if x in [12, 1, 2]:  # Dec, Jan, Feb -> Winter\n",
    "        return 'Winter'\n",
    "    elif x in [3, 4, 5]:  # Mar, Apr, May -> Spring\n",
    "        return 'Spring'\n",
    "    elif x in [6, 7, 8]:  # Jun, Jul, Aug -> Summer\n",
    "        return 'Summer'\n",
    "    elif x in [9, 10, 11]:  # Sep, Oct, Nov -> Fall\n",
    "        return 'Fall'\n",
    "\n",
    "# Apply function to get the Season column\n",
    "# season_df['Season'] = season_df['Month_Number'].apply(month_num_to_name)\n",
    "season_df.loc[season_df['Month_Number'] == 12, 'Month_Number'] = 0\n",
    "season_df = season_df.sort_values(by='Month_Number')\n",
    "season_df\n",
    "\n",
    "season_df['Month_Name'] = ['Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov']\n",
    "season_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74401e10-89f6-4000-8171-ead8f2d5e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=season_df, x = season_df['Month_Name'], y='Count', hue='Season', marker='o', palette='rainbow')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Hourly Distribution by Season\")\n",
    "plt.xticks(range(0, 12))  # Show full range of hours\n",
    "plt.legend(title=\"Season\")\n",
    "\n",
    "# Show plot\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.savefig('images/fig5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767cc4b-bacc-4d7a-9de4-628e78bdf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b691c-d529-4584-9651-210dc820a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.to_csv('datasets/locations.csv')\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0073d99-e142-4be1-8b08-812e8681a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['End Station Id'] = sample_df['End Station Id'].astype(np.int64)\n",
    "sample_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d953d-c1fc-414a-b6cf-702612b27af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df1 has station_id and lat/lon columns\n",
    "# and df2 has Start_Station_ID and End_Station_ID to merge with\n",
    "\n",
    "df_merged = pd.merge(sample_df, locations, left_on='Start Station Id', right_on='station_id', how='left')\n",
    "df_merged = pd.merge(df_merged, locations, left_on='End Station Id', right_on='station_id', how='left', suffixes=('_start', '_end'))\n",
    "\n",
    "df_merged\n",
    "\n",
    "df_merged.to_csv(\"datasets/lon-lat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c11f0a-e0a1-436f-809a-0ae46ecba07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium as folium\n",
    "\n",
    "# Example list of tuples (latitude, longitude)\n",
    "route = [\n",
    "    (43.63985, -79.395989),\n",
    "    (43.64012, -79.395672),\n",
    "    (43.64045, -79.395321),\n",
    "    (43.64100, -79.394956)\n",
    "]\n",
    "\n",
    "# Create a map centered around the first point\n",
    "mymap = folium.Map(location=route[0], zoom_start=15)\n",
    "\n",
    "# Add the route as a polyline\n",
    "folium.PolyLine(route, color=\"blue\", weight=2.5, opacity=1).add_to(mymap)\n",
    "\n",
    "# Add markers for each point in the route\n",
    "for lat, lon in route:\n",
    "    folium.Marker([lat, lon]).add_to(mymap)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "mymap.save(\"route_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e531c42-e475-41bc-ae5e-a732b4227e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
